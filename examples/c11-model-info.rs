//! Example showing how to get model information using the client

use genai::{adapter::AdapterKind, resolver::{AuthData, Endpoint, ServiceTargetResolver}, Client, ModelIden, ServiceTarget};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
	println!("=== æ¨¡å‹ä¿¡æ¯ç¤ºä¾‹ ===\n");

	// è¦æŸ¥è¯¢çš„é€‚é…å™¨ç±»å‹
	const ADAPTER_KINDS: &[AdapterKind] = &[
		AdapterKind::OpenAI,
		AdapterKind::Anthropic,
		AdapterKind::Gemini,
		AdapterKind::Cohere,
		AdapterKind::Groq,
		AdapterKind::DeepSeek,
		AdapterKind::Xai,
		// AdapterKind::Ollama, // æ³¨é‡Šæ‰ Ollamaï¼Œå› ä¸ºå®ƒéœ€è¦æœ¬åœ°æœåŠ¡è¿è¡Œ
	];

	let client = Client::default();

	for &adapter_kind in ADAPTER_KINDS {
		println!("\nğŸ” è·å– {} çš„æ¨¡å‹ä¿¡æ¯...", adapter_kind);
		
		match client.all_models(adapter_kind).await {
			Ok(models) => {
				if models.is_empty() {
					println!("   âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹");
					continue;
				}

				println!("   âœ… æ‰¾åˆ° {} ä¸ªæ¨¡å‹:\n", models.len());
				
				for (index, model) in models.iter().enumerate() {
					println!("   ğŸ“‹ æ¨¡å‹ #{}: {}", index + 1, model.name);
					println!("      æ¨¡å‹ ID: {}", model.id);
					println!("      é€‚é…å™¨ç±»å‹: {}", adapter_kind);
					
					// æ˜¾ç¤ºæ”¯æŒçš„åŠŸèƒ½
					let mut features = Vec::new();
					if model.supports_tool_calls {
						features.push("ğŸ”§ å·¥å…·è°ƒç”¨");
					}
					if model.supports_streaming {
						features.push("ğŸŒŠ æµå¼å“åº”");
					}
					if model.supports_json_mode {
						features.push("ğŸ“„ JSON æ¨¡å¼");
					}
					if model.supports_reasoning {
						features.push("ğŸ§  æ¨ç†èƒ½åŠ›");
					}
					if model.is_multimodal() {
						features.push("ğŸ–¼ï¸ å¤šæ¨¡æ€");
					}
					
					if !features.is_empty() {
						println!("      æ”¯æŒçš„åŠŸèƒ½: {}", features.join(", "));
					}
					
					// æ˜¾ç¤ºä»¤ç‰Œé™åˆ¶
					if let Some(input_limit) = model.effective_input_token_limit() {
						println!("      è¾“å…¥ä»¤ç‰Œé™åˆ¶: {}", input_limit);
					}
					if let Some(output_limit) = model.effective_output_token_limit() {
						println!("      è¾“å‡ºä»¤ç‰Œé™åˆ¶: {}", output_limit);
					}
					
					// æ˜¾ç¤ºæ”¯æŒçš„æ¨¡æ€
					if model.is_multimodal() {
						println!("      è¾“å…¥æ¨¡æ€: {:?}", model.supported_input_modalities);
						println!("      è¾“å‡ºæ¨¡æ€: {:?}", model.supported_output_modalities);
					}
					
					// æ˜¾ç¤ºæ¨ç†èƒ½åŠ›è¯¦æƒ…
					if model.supports_reasoning {
						if let Some(ref efforts) = model.supported_reasoning_efforts {
							if !efforts.is_empty() {
								println!("      æ”¯æŒçš„æ¨ç†å¼ºåº¦: {:?}", efforts);
							}
						}
					}
					
					println!();
				}
			}
			Err(e) => {
				println!("   âŒ è·å–æ¨¡å‹å¤±è´¥: {}", e);
				// å¦‚æœæ˜¯å› ä¸º API å¯†é’¥é—®é¢˜ï¼Œç»™å‡ºå‹å¥½çš„æç¤º
				if let Some(env_name) = adapter_kind.default_key_env_name() {
					println!("      ğŸ’¡ æç¤º: è¯·ç¡®ä¿è®¾ç½®äº†ç¯å¢ƒå˜é‡ {}", env_name);
				}
			}
		}
	}

	println!("\nğŸ“ æ³¨æ„äº‹é¡¹:");
	println!("   â€¢ å¤§éƒ¨åˆ†é€‚é…å™¨ä½¿ç”¨é™æ€æ¨¡å‹åˆ—è¡¨");
	println!("   â€¢ Ollama é€‚é…å™¨ä¼šåŠ¨æ€æŸ¥è¯¢æœ¬åœ°æœåŠ¡");
	println!("   â€¢ éœ€è¦è®¾ç½®ç›¸åº”çš„ API å¯†é’¥ç¯å¢ƒå˜é‡");
	println!("   â€¢ æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦ç‰¹æ®Šæƒé™æ‰èƒ½è®¿é—®");

	Ok(())
} 